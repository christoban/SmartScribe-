from celery import Celery
from app.core.config import get_settings
from app.core.logger import get_logger
from celery.schedules import crontab  # 1. Ajoute cet import en haut

settings = get_settings()
logger = get_logger("celery_app")

celery_app = Celery(
    "smartscribe",
    broker=settings.REDIS_URL,
    backend=settings.REDIS_URL
)

celery_app.conf.update(
    # --- S√©curit√© & Format ---
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="UTC",
    enable_utc=True,

    # --- Robustesse (Essentiel pour l'IA) ---
    task_acks_late=True,           # La t√¢che reste dans Redis si le worker crash
    task_reject_on_worker_lost=True,
    task_time_limit=3600,          # 1h max pour √©viter les process fant√¥mes
    
    # --- Performance GPU/RAM ---
    worker_prefetch_multiplier=1,  # Ne r√©serve qu'une t√¢che √† la fois
    worker_concurrency=1,          # RECOMMAND√â : 1 seul process lourd √† la fois sur Windows
)

# 2. Ajoute le planning ici (C'est le "m√©tronome" de Celery)
celery_app.conf.beat_schedule = {
    "cleanup-exports-every-hour": {
        "task": "cleanup_exports_task", # Le nom exact d√©fini dans @celery_app.task
        "schedule": crontab(minute=0),   # S'ex√©cute √† chaque heure pile (:00)
        "args": (24,),                  # On passe l'argument max_age_hours
    },
}

# --- D√©tection automatique des t√¢ches ---
# On pointe vers le dossier o√π nous allons mettre nos fichiers de t√¢ches
celery_app.autodiscover_tasks([
    "app.services.tasks.cleanup_exports_task",
    "app.services.tasks.process_full_media",
    "app.services.tasks.worker"
], force=True)

@celery_app.task(name="check_health")
def check_health():
    logger.info("üöÄ Celery Worker est en ligne et pr√™t pour ScolarAI !")
    return "OK"

logger.info("[START] Celery configur√© pour le traitement IA...")