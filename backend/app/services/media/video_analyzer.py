"""
Service d'analyse vid√©o - Extraction de keyframes (images cl√©s)
"""
from __future__ import annotations

from pathlib import Path
from typing import List, Optional
import cv2
from app.core.logger import get_logger

class VideoAnalyzer:
    """Analyse les vid√©os et extrait des images cl√©s (keyframes)"""
    
    def __init__(self):
        self.logger = get_logger("video_analyzer")
    
    def extract_keyframes(
        self,
        video_path: str | Path,
        output_dir: Optional[str | Path] = None,
        interval_seconds: int = 30,
        max_frames: Optional[int] = None
    ) -> List[Path]:
        """
        Extrait des images cl√©s d'une vid√©o
        
        Args:
            video_path: Chemin vers la vid√©o
            output_dir: R√©pertoire de sortie (optionnel)
            interval_seconds: Intervalle en secondes entre chaque keyframe
            max_frames: Nombre maximum de frames √† extraire
        
        Returns:
            Liste des chemins des images extraites
        """
        video_path_obj = Path(video_path)
        if not video_path_obj.exists():
            raise FileNotFoundError(f"Vid√©o non trouv√©e: {video_path}")
        
        # D√©terminer le r√©pertoire de sortie
        if output_dir:
            output_path = Path(output_dir)
        else:
            output_path = video_path_obj.parent / "keyframes"
        
        output_path.mkdir(parents=True, exist_ok=True)
        
        # Ouvrir la vid√©o
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            raise ValueError(f"Impossible d'ouvrir la vid√©o: {video_path}")
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_interval = int(fps * interval_seconds)
        
        extracted_frames: List[Path] = []
        frame_count = 0
        saved_count = 0
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # Extraire une frame tous les X frames
                if frame_count % frame_interval == 0:
                    if max_frames and saved_count >= max_frames:
                        break
                    
                    frame_filename = f"keyframe_{saved_count:04d}_{frame_count}.jpg"
                    frame_path = output_path / frame_filename
                    
                    cv2.imwrite(str(frame_path), frame)
                    extracted_frames.append(frame_path)
                    saved_count += 1
                    
                    self.logger.info(f"üì∏ Keyframe extraite: {frame_filename}")
                
                frame_count += 1
            
            self.logger.info(f"‚úÖ {saved_count} keyframes extraites de {video_path}")
            
        finally:
            cap.release()
        
        return extracted_frames
    
    def extract_slides(
        self,
        video_path: str | Path,
        output_dir: Optional[str | Path] = None,
        similarity_threshold: float = 0.95
    ) -> List[Path]:
        """
        Extrait les slides/diapositives d'une vid√©o en d√©tectant les changements significatifs
        
        Args:
            video_path: Chemin vers la vid√©o
            output_dir: R√©pertoire de sortie
            similarity_threshold: Seuil de similarit√© pour d√©tecter un changement de slide
        
        Returns:
            Liste des chemins des slides extraites
        """
        video_path_obj = Path(video_path)
        if output_dir:
            output_path = Path(output_dir)
        else:
            output_path = video_path_obj.parent / "slides"
        
        output_path.mkdir(parents=True, exist_ok=True)
        
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            raise ValueError(f"Impossible d'ouvrir la vid√©o: {video_path}")
        
        extracted_slides: List[Path] = []
        prev_frame = None
        slide_count = 0
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                if prev_frame is not None:
                    # Calculer la similarit√© entre les frames
                    similarity = self._calculate_similarity(prev_frame, frame)
                    
                    if similarity < similarity_threshold:
                        # Changement significatif d√©tect√© - probablement une nouvelle slide
                        slide_filename = f"slide_{slide_count:04d}.jpg"
                        slide_path = output_path / slide_filename
                        cv2.imwrite(str(slide_path), frame)
                        extracted_slides.append(slide_path)
                        slide_count += 1
                        self.logger.info(f"üìä Slide d√©tect√©e: {slide_filename}")
                
                prev_frame = frame.copy()
            
            self.logger.info(f"‚úÖ {slide_count} slides extraites")
            
        finally:
            cap.release()
        
        return extracted_slides
    
    def _calculate_similarity(self, frame1, frame2) -> float:
        """Calcule la similarit√© entre deux frames"""
        # Convertir en niveaux de gris
        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)
        
        # Calculer la corr√©lation
        result = cv2.matchTemplate(gray1, gray2, cv2.TM_CCOEFF_NORMED)
        similarity = result[0][0]
        
        return similarity

# Instance globale
video_analyzer = VideoAnalyzer()
